<feed xmlns="http://www.w3.org/2005/Atom"> <id>/</id><title>Max van Dijck</title><subtitle>Max van Dijck, Aspiring Machine Learning Practitioner and Data Science.</subtitle> <updated>2022-07-14T16:14:55+12:00</updated> <author> <name>Max van Dijck</name> <uri>/</uri> </author><link rel="self" type="application/atom+xml" href="/feed.xml"/><link rel="alternate" type="text/html" hreflang="en-US" href="/"/> <generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator> <rights> © 2022 Max van Dijck </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Performance of Symbolic &amp; Connectionist AI in Image Recognition</title><link href="/posts/Performance-of-Symbolic-&amp;-Connectionist-AI-in-Image-Recognition/" rel="alternate" type="text/html" title="Performance of Symbolic &amp; Connectionist AI in Image Recognition" /><published>2021-06-17T08:55:00+12:00</published> <updated>2021-06-17T08:55:00+12:00</updated> <id>/posts/Performance-of-Symbolic-&amp;-Connectionist-AI-in-Image-Recognition/</id> <content src="/posts/Performance-of-Symbolic-&amp;-Connectionist-AI-in-Image-Recognition/" /> <author> <name>Max van Dijck</name> </author> <category term="Research" /> <summary> Neural network approaches in the field of artificial intelligence (AI) have accelerated in popularity over the past decade in the academic field. This surge has arguably left behind import concerns in intelligent machines such as interpretability and robustness. This raises questions around the trade-off of performance and aforementioned concerns when choosing between symbolic and connectionist... </summary> </entry> <entry><title>Tricks for Training a State-of-the-art Deep Learning model for Computer Vision in Fast.AI</title><link href="/posts/Tricks-for-Training-a-State-of-the-art-Deep-Learning-model-for-Computer-Vision-in-Fast-AI/" rel="alternate" type="text/html" title="Tricks for Training a State-of-the-art Deep Learning model for Computer Vision in Fast.AI" /><published>2021-05-07T21:00:00+12:00</published> <updated>2021-05-07T21:00:00+12:00</updated> <id>/posts/Tricks-for-Training-a-State-of-the-art-Deep-Learning-model-for-Computer-Vision-in-Fast-AI/</id> <content src="/posts/Tricks-for-Training-a-State-of-the-art-Deep-Learning-model-for-Computer-Vision-in-Fast-AI/" /> <author> <name>Max van Dijck</name> </author> <category term="Tutorial" /> <summary> There exists many ways to easily and effectively improve the accuracy of a neural network simply by making small changes to the data, training pipeline or how we run inference. This post aims to outline the most common, effective techniques, how they work and how they’re implemented in fast.ai. Data Augmentation Data augmentation is the act of taking your training data and creating brand new ... </summary> </entry> </feed>
